# COMMANDS.md ‚Äî Scalp Radar Commandes & M√©thodologie

## R√®gles pour l'IA

**Ce fichier est la r√©f√©rence pour toutes les commandes CLI du projet.**
Quand l'utilisateur demande "montre-moi les r√©sultats", "lance un backtest", "v√©rifie l'√©tat du serveur", etc., utiliser les commandes ci-dessous. Ne pas improviser ‚Äî ces commandes sont test√©es et fonctionnent.

**PowerShell (Windows local) :** Toutes les commandes locales utilisent PowerShell.
Attention aux quotes : utiliser `"` pour les strings Python, cr√©er un fichier .py temporaire si les quotes imbriqu√©es posent probl√®me.

**Bash (serveur Linux prod) :** Pr√©fixer avec `docker exec scalp-radar-backend-1` pour ex√©cuter dans le container.

---

## üö® COMMANDES D'URGENCE LIVE

> Toutes les commandes suivantes s'ex√©cutent **sur le serveur** (`ssh jack@192.168.1.200`, dans `~/scalp-radar`).
> Pour le rollback git, la purge √©tat et la d√©sactivation strat√©gie ‚Üí voir **¬ß 18. Rollback d'urgence**.
> Pour un guide de d√©pannage complet (sympt√¥mes ‚Üí diagnostic ‚Üí fix) ‚Üí voir **[docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)**.

### Reset Kill Switch Live

```bash
curl -X POST http://localhost:8000/api/executor/kill-switch/reset \
  -H "X-API-Key: $(grep SYNC_API_KEY .env | cut -d= -f2)"
```

### Status Executor (JSON format√©)

```bash
curl -s http://localhost:8000/api/executor/status \
  -H "X-API-Key: $(grep SYNC_API_KEY .env | cut -d= -f2)" | python3 -m json.tool
```

### V√©rifier Kill Switch dans les logs

```bash
docker compose logs backend --since 5m | grep -i "kill_switch"
```

### V√©rifier Exit Monitor

```bash
docker compose logs backend --since 10m | grep -E "(Exit monitor|EXIT AUTONOME|no exit)"
```

### Logs positions ouvertes/ferm√©es + erreurs

```bash
# Activit√© grids r√©cente
docker compose logs backend --since 1h | grep -E "(GRID CLOSE|GRID ENTRY|EXIT AUTONOME)" | tail -20
# Erreurs critiques
docker compose logs backend --since 1h | grep -E "(ERROR|CRITICAL)" | tail -20
# Boot sync
docker compose logs backend --since 5m | grep -i "sync\|restore\|warm-up"
```

### Reset d'urgence de l'√©tat executor (DERNIER RECOURS)

> ‚ö†Ô∏è Utiliser uniquement si le bot est arr√™t√© et que l'√©tat JSON est corrompu.
> Fermer toutes les positions sur Bitget manuellement AVANT.

```bash
docker compose stop backend
python3 -c "
import json
with open('data/executor_state.json') as f:
    state = json.load(f)
state.setdefault('executor', {}).update({
    'risk_manager': {'kill_switch': False, 'session_pnl': 0.0},
    'grid_states': {},
    'positions': {},
})
with open('data/executor_state.json', 'w') as f:
    json.dump(state, f, indent=2)
print('State reset OK')
"
docker compose start backend
```

---

## 1. R√©sultats WFO / Grades

### Voir tous les grades (toutes strat√©gies, derniers r√©sultats)
```powershell
uv run python -c "import sqlite3; conn = sqlite3.connect('data/scalp_radar.db'); rows = conn.execute('SELECT strategy_name, asset, grade, total_score, oos_sharpe, consistency FROM optimization_results WHERE is_latest=1 ORDER BY strategy_name, total_score DESC').fetchall(); [print(f'{r[0]:20} {r[1]:14} Grade {r[2]}  ({r[3]:3.0f})  Sharpe {r[4]:5.2f}  Consist {r[5]:.0%}') for r in rows]; conn.close()"
```

### Voir les grades d'une strat√©gie sp√©cifique
```powershell
uv run python -c "import sqlite3; conn = sqlite3.connect('data/scalp_radar.db'); rows = conn.execute(""SELECT asset, grade, total_score, oos_sharpe, consistency FROM optimization_results WHERE strategy_name='envelope_dca' AND is_latest=1 ORDER BY total_score DESC"").fetchall(); [print(f'{r[0]:14} Grade {r[1]}  ({r[2]:3.0f})  Sharpe {r[3]:5.2f}  Consist {r[4]:.0%}') for r in rows]; conn.close()"
```

### Voir l'analyse par r√©gime (cr√©er un fichier temporaire si quotes complexes)
```powershell
@"
import sqlite3, json
conn = sqlite3.connect('data/scalp_radar.db')
rows = conn.execute(
    "SELECT asset, regime_analysis FROM optimization_results "
    "WHERE strategy_name='envelope_dca' AND is_latest=1 AND regime_analysis IS NOT NULL "
    "ORDER BY total_score DESC LIMIT 10"
).fetchall()
for asset, ra_json in rows:
    if ra_json:
        ra = json.loads(ra_json)
        print(f"\n=== {asset} ===")
        for regime in ["bull","bear","range","crash"]:
            d = ra.get(regime, {})
            if d:
                sharpe = d.get("avg_oos_sharpe", 0)
                consist = d.get("consistency", 0) * 100
                wins = d.get("n_windows", 0)
                print(f"  {regime:6}: Sharpe {sharpe:6.2f}  Consist {consist:4.0f}%  Windows {wins}")
conn.close()
"@ | Out-File -Encoding utf8 _tmp_query.py
uv run python _tmp_query.py
del _tmp_query.py
```

### Voir les r√©sultats sur le serveur prod
```bash
ssh jack@192.168.1.200
docker exec scalp-radar-backend-1 uv run python -c "import sqlite3; conn = sqlite3.connect('data/scalp_radar.db'); rows = conn.execute('SELECT strategy_name, asset, grade, total_score FROM optimization_results WHERE is_latest=1 ORDER BY strategy_name, total_score DESC').fetchall(); [print(f'{r[0]:20} {r[1]:14} Grade {r[2]} ({r[3]:3.0f})') for r in rows]; conn.close()"
```

---

## 2. Lancer des optimisations WFO

### Optimiser une strat√©gie sur un asset
```powershell
uv run python -m scripts.optimize --strategy envelope_dca --symbol BTC/USDT -v
```

### Optimiser une strat√©gie sur tous les assets
```powershell
uv run python -m scripts.optimize --strategy envelope_dca --all-symbols -v
```

### Optimiser toutes les strat√©gies, tous les assets
```powershell
uv run python -m scripts.optimize --all
```

### Boucle sur plusieurs assets (PowerShell)
```powershell
foreach ($s in @("BTC/USDT","ETH/USDT","SOL/USDT","DOGE/USDT","LINK/USDT")) {
    Write-Host "=== envelope_dca $s ==="
    uv run python -m scripts.optimize --strategy envelope_dca --symbol $s
}
```

### Boucle sur les 15 altcoins (hors Top 6)
```powershell
foreach ($s in @("ADA/USDT","AAVE/USDT","ARB/USDT","AVAX/USDT","BCH/USDT","BNB/USDT","CRV/USDT","DYDX/USDT","FET/USDT","GALA/USDT","ICP/USDT","NEAR/USDT","OP/USDT","SUI/USDT","UNI/USDT")) {
    Write-Host "=== envelope_dca $s ==="
    uv run python -m scripts.optimize --strategy envelope_dca --symbol $s
}
```

### Appliquer les r√©sultats A/B dans strategies.yaml
```powershell
uv run python -m scripts.optimize --all --apply
```

### Flags Sprint 37 ‚Äî Timeframe Coherence Guard

| Flag | Description |
| ---- | ----------- |
| `--force-timeframe 1h` | Restreint la grid WFO √† un seul TF (override `param_grids.yaml`) |
| `--symbols A,B,C` | Optimise plusieurs assets s√©par√©s par virgule (mutex avec `--symbol` / `--all-symbols`) |
| `--exclude A,B` | Exclut des assets de `--apply` (les retire du YAML s'ils y sont) |
| `--ignore-tf-conflicts` | Force `--apply` en excluant silencieusement les outliers TF |

**Workflow r√©solution conflit timeframe** (affich√© automatiquement si `--apply` d√©tecte un outlier) :

```powershell
# 1. Voir les outliers ‚Üí --apply affiche le message bloquant avec les 3 actions
uv run python -m scripts.optimize --strategy grid_atr --apply

# 2a. Re-tester les outliers en 1h (recommand√©)
uv run python -m scripts.optimize --strategy grid_atr --symbols BCH/USDT,BNB/USDT --force-timeframe 1h

# 2b. Exclure les outliers et appliquer
uv run python -m scripts.optimize --strategy grid_atr --apply --exclude BCH/USDT,BNB/USDT

# 2c. Forcer (exclut les outliers silencieusement, sans re-tester)
uv run python -m scripts.optimize --strategy grid_atr --apply --ignore-tf-conflicts

# Portfolio backtest ‚Äî bloque si un runner a un timeframe ‚â† 1h (TimeframeConflictError)
# Affiche les assets conflictuels + suggestions --force-timeframe
uv run python -m scripts.portfolio_backtest --strategy grid_atr --days 365
```

---

### Reprendre un WFO interrompu (--resume)

Skippe les assets d√©j√† en DB (`is_latest=1`) ‚Äî utile apr√®s un crash OOM/segfault.

```powershell
# Reprendre grid_range_atr apr√®s crash (ex: plant√© √† UNI/USDT)
uv run python -m scripts.optimize --strategy grid_range_atr --all-symbols --resume

# Voir quels assets sont d√©j√† faits avant de lancer
uv run python -m scripts.optimize --strategy grid_range_atr --all-symbols --resume --dry-run
```

| Argument   | D√©faut | Description                                          |
|------------|--------|------------------------------------------------------|
| `--resume` | false  | Skipper les assets d√©j√† en DB (reprend apr√®s crash)  |

---

### Recalculer les grades sans re-WFO (--regrade)

Recalcule le score et le grade √† partir des r√©sultats OOS d√©j√† en DB. Utile apr√®s un changement de formule combo_score ou de seuil de grading.

```powershell
uv run python -m scripts.optimize --regrade --strategy grid_atr
uv run python -m scripts.optimize --regrade --strategy grid_multi_tf
```

> Incompatible avec `--apply`, `--symbol`, `--symbols`, `--all-symbols`, `--all`, `--resume`.

---

### Optimiser grid_boltrend (source binance)

```powershell
# Asset unique
uv run python -m scripts.optimize --strategy grid_boltrend --symbol ETH/USDT --exchange binance -v

# Boucle Top assets
foreach ($s in @("BTC/USDT","ETH/USDT","DOGE/USDT","DYDX/USDT","LINK/USDT")) {
    Write-Host "=== grid_boltrend $s ==="
    uv run python -m scripts.optimize --strategy grid_boltrend --symbol $s --exchange binance
}

# Tous les assets
uv run python -m scripts.optimize --strategy grid_boltrend --all-symbols --exchange binance
```

---

## 3. Donn√©es historiques

### V√©rifier les donn√©es disponibles
```powershell
uv run python -m scripts.optimize --check-data
```

### Fetch donn√©es 1h (backtest principal)

```powershell
# Tous les 21 assets depuis assets.yaml (sans --symbol = tous par d√©faut)
uv run python -m scripts.fetch_history --exchange binance --days 1100 --timeframe 1h

# Assets sp√©cifiques
uv run python -m scripts.fetch_history --exchange binance --days 1100 --symbols BTC/USDT,ETH/USDT,SOL/USDT --timeframe 1h

# Bitget pour validation cross-exchange (~90j)
uv run python -m scripts.fetch_history --exchange bitget --days 90 --timeframe 1h
```

### Fetch donn√©es courtes (indicateurs Scanner ‚Äî 7 jours)
```powershell
uv run python -m scripts.fetch_history --exchange binance --days 7 --symbols ADA/USDT,XRP/USDT --timeframe 5m
uv run python -m scripts.fetch_history --exchange binance --days 7 --symbols ADA/USDT,XRP/USDT --timeframe 15m
```

### Backfill candles Binance (API publique, sans cl√©)
```powershell
uv run python -m scripts.backfill_candles --symbol BTC/USDT --timeframe 1h --days 1800
# Depuis une date pr√©cise
uv run python -m scripts.backfill_candles --symbol ETH/USDT --timeframe 1h --since 2022-01-01
```

### Fetch funding rates historiques (requis pour grid_funding)

```powershell
# Tous les assets depuis assets.yaml (720 jours)
uv run python -m scripts.fetch_funding

# Asset sp√©cifique
uv run python -m scripts.fetch_funding --symbol BTC/USDT --days 720

# Force re-fetch (supprime existant)
uv run python -m scripts.fetch_funding --symbol ETH/USDT --force
```

### Fetch open interest historique (requis pour momentum/liquidation)

```powershell
# Tous les assets (5m, 720 jours)
uv run python -m scripts.fetch_oi

# Asset + timeframe sp√©cifique
uv run python -m scripts.fetch_oi --symbol BTC/USDT --timeframe 1h --days 365

# Timeframes disponibles : 5m, 15m, 30m, 1h, 4h, 1d
uv run python -m scripts.fetch_oi --symbol SOL/USDT --timeframe 4h --force
```

---

## 4. Simulator / Paper Trading

### Reset simulator (efface state, repart √† initial_capital)
```powershell
uv run python scripts/reset_simulator.py
```

### Lancer le serveur local (dev)
```powershell
.\dev.bat
# ou manuellement :
uv run uvicorn backend.api.server:app --reload --host 127.0.0.1 --port 8000
```

### V√©rifier l'√©tat du grid (positions ouvertes)
```
GET http://127.0.0.1:8000/api/simulator/grid-state
```

### V√©rifier la sant√©
```
GET http://127.0.0.1:8000/health
```

### Voir les trades r√©cents
```
GET http://127.0.0.1:8000/api/simulator/trades?limit=20
```

### Voir les conditions de march√©
```
GET http://127.0.0.1:8000/api/simulator/conditions
```

---

## 5. Tests

### Lancer tous les tests
```powershell
uv run python -m pytest --tb=short -q
```

### Lancer un fichier de test sp√©cifique
```powershell
uv run python -m pytest tests/test_multi_engine.py --tb=short -q
```

### Lancer un test sp√©cifique
```powershell
uv run python -m pytest tests/test_multi_engine.py::TestEnvelopeDCA::test_asymmetric_envelopes -v
```

### Lancer avec couverture
```powershell
uv run python -m pytest --cov=backend --cov-report=term-missing --tb=short -q
```

---

## 6. D√©ploiement Production

### D√©ployer (pr√©serve le state)
```bash
ssh jack@192.168.1.200
cd ~/scalp-radar
git pull
bash deploy.sh
```

### D√©ployer (fresh start ‚Äî efface le state JSON, pas la DB)
```bash
bash deploy.sh --clean
```

### Voir les logs prod
```bash
docker compose logs -f backend
docker compose logs --tail 100 backend
```

### V√©rifier le health
```bash
curl http://localhost:8000/health | python3 -m json.tool
```

### V√©rifier le sync
```bash
docker exec scalp-radar-backend-1 env | grep SYNC
```

---

## 7. Requ√™tes DB courantes

### Compter les tests dans la DB
```powershell
uv run python -c "import sqlite3; conn = sqlite3.connect('data/scalp_radar.db'); print('Trades:', conn.execute('SELECT COUNT(*) FROM trades').fetchone()[0]); print('WFO results:', conn.execute('SELECT COUNT(*) FROM optimization_results').fetchone()[0]); conn.close()"
```

### Voir les trades paper r√©cents
```powershell
uv run python -c "import sqlite3; conn = sqlite3.connect('data/scalp_radar.db'); rows = conn.execute('SELECT symbol, direction, entry_price, exit_price, net_pnl, exit_reason, created_at FROM trades ORDER BY created_at DESC LIMIT 10').fetchall(); [print(f'{r[0]:14} {r[1]:5} entry={r[2]:10.4f} exit={r[3]:10.4f} pnl={r[4]:+8.2f} {r[5]:10} {r[6]}') for r in rows]; conn.close()"
```

### Voir le P&L par asset
```powershell
uv run python -c "import sqlite3; conn = sqlite3.connect('data/scalp_radar.db'); rows = conn.execute('SELECT symbol, COUNT(*) as n, SUM(net_pnl) as total_pnl, AVG(net_pnl) as avg_pnl FROM trades GROUP BY symbol ORDER BY total_pnl DESC').fetchall(); [print(f'{r[0]:14} {r[1]:4} trades  P&L={r[2]:+10.2f}  avg={r[3]:+8.2f}') for r in rows]; conn.close()"
```

### Voir le nombre de combos WFO par run
```powershell
uv run python -c "import sqlite3; conn = sqlite3.connect('data/scalp_radar.db'); rows = conn.execute('SELECT r.strategy_name, r.asset, r.grade, COUNT(c.id) as combos FROM optimization_results r LEFT JOIN wfo_combo_results c ON r.id = c.result_id WHERE r.is_latest=1 GROUP BY r.id ORDER BY r.strategy_name, r.total_score DESC').fetchall(); [print(f'{r[0]:20} {r[1]:14} Grade {r[2]}  {r[3]:4} combos') for r in rows]; conn.close()"
```

---

## 8. Config v√©rifications

### Voir les assets actifs
```powershell
uv run python -c "from backend.core.config import get_config; c = get_config(); print(f'{len(c.assets)} assets:'); [print(f'  {a.symbol}') for a in c.assets]"
```

### Voir les strat√©gies activ√©es
```powershell
uv run python -c "from backend.strategies.factory import get_enabled_strategies; from backend.core.config import get_config; strats = get_enabled_strategies(get_config()); [print(f'  {s.name}') for s in strats]"
```

### Voir le capital et risk config
```powershell
uv run python -c "from backend.core.config import get_config; c = get_config(); print(f'Initial capital: {c.risk.initial_capital}'); print(f'Max concurrent: {c.risk.max_concurrent_positions}'); print(f'Kill switch: {c.risk.global_kill_switch_pct}/{c.risk.global_kill_switch_window_hours}h')"
```

### Voir les per_asset d'une strat√©gie
```powershell
uv run python -c "from backend.core.config import get_config; c = get_config(); pa = c.strategies.envelope_dca.per_asset; print(f'{len(pa)} per_asset overrides:'); [print(f'  {k}: sl={v.get(\"sl_percent\",\"?\")}% levels={v.get(\"num_levels\",\"?\")}') for k,v in sorted(pa.items())]"
```

---

## 9. Patterns PowerShell pour queries complexes

### Pattern "fichier temporaire" (√©vite les probl√®mes de quotes)
```powershell
@"
# Code Python ici, avec des quotes normales
import sqlite3
conn = sqlite3.connect("data/scalp_radar.db")
# ... requ√™te ...
conn.close()
"@ | Out-File -Encoding utf8 _tmp_query.py
uv run python _tmp_query.py
del _tmp_query.py
```

### Pattern "boucle parall√®le" (3 terminaux)
```powershell
# Terminal 1
foreach ($s in @("BTC/USDT","ETH/USDT","SOL/USDT")) { uv run python -m scripts.optimize --strategy grid_atr --symbol $s }

# Terminal 2
foreach ($s in @("DOGE/USDT","LINK/USDT","ADA/USDT")) { uv run python -m scripts.optimize --strategy grid_atr --symbol $s }

# Terminal 3
foreach ($s in @("AAVE/USDT","ARB/USDT","AVAX/USDT")) { uv run python -m scripts.optimize --strategy grid_atr --symbol $s }
```

---

## 10. M√©thodologie de travail

### Workflow Claude (discussion) + Claude Code (impl√©mentation)
1. **Claude (ce chat)** : discute, analyse, r√©dige les briefs/plans pour Claude Code
2. **Claude Code** : impl√©mente le code, lance les tests, fait les commits
3. **Jack** : valide visuellement, teste en local, d√©ploie en prod

### Avant chaque sprint
1. V√©rifier les tests : `uv run python -m pytest --tb=short -q`
2. V√©rifier le nombre de tests actuel (dans le output pytest)
3. Lire CLAUDE.md et ROADMAP.md pour le contexte

### Apr√®s chaque sprint
1. Mettre √† jour CLAUDE.md (test count, nouvelles features)
2. Mettre √† jour ROADMAP.md (sprint compl√©t√©, r√©sultats, le√ßons)
3. D√©ployer en prod : `git pull && bash deploy.sh`
4. V√©rifier visuellement le dashboard

### Pour ajouter une nouvelle strat√©gie grid

Voir [STRATEGIES.md ¬ß Comment ajouter une nouvelle strat√©gie](docs/STRATEGIES.md#comment-ajouter-une-nouvelle-strat√©gie) (checklist 11 √©tapes).

Pour le workflow complet validation (WFO ‚Üí Grade ‚Üí Portfolio ‚Üí Paper ‚Üí Live), voir [WORKFLOW_WFO.md](docs/WORKFLOW_WFO.md).

---

## 11. Backtest individuel (run_backtest)

Lance un backtest simple sur une strat√©gie + asset avec le BacktestEngine event-driven.

```powershell
# Backtest vwap_rsi sur BTC/USDT, 90 jours
uv run python -m scripts.run_backtest --strategy vwap_rsi --symbol BTC/USDT --days 90

# Avec capital et levier personnalis√©s
uv run python -m scripts.run_backtest --strategy bollinger_mr --symbol ETH/USDT --days 180 --capital 5000 --leverage 5

# Sortie JSON (pour inspection programmatique)
uv run python -m scripts.run_backtest --strategy grid_atr --symbol BTC/USDT --json

# √âcrire dans un fichier
uv run python -m scripts.run_backtest --strategy grid_atr --symbol BTC/USDT --output results/grid_atr_btc.json --json
```

**Arguments disponibles :**

| Argument | D√©faut | Description |
| --- | --- | --- |
| `--strategy` | `vwap_rsi` | Strat√©gie √† tester |
| `--symbol` | `BTC/USDT` | Paire √† tester |
| `--days` | `90` | Nombre de jours de donn√©es |
| `--capital` | `10000` | Capital initial ($) |
| `--leverage` | depuis risk.yaml | Levier |
| `--json` | false | Sortie JSON au lieu du tableau |
| `--output` | ‚Äî | Fichier de sortie |

---

## 12. Portfolio Backtest (portfolio_backtest)

Simule N assets avec capital partag√© (m√™me code que la prod). Voir section 2 pour les exemples WFO.

```powershell
# Auto-d√©tection historique (d√©faut) ‚Äî affiche le goulot par asset
uv run python -m scripts.portfolio_backtest --strategy grid_atr --capital 10000

# grid_atr sur les Top 10 assets paper, 365 jours
uv run python -m scripts.portfolio_backtest --strategy grid_atr --assets BTC/USDT,AVAX/USDT,CRV/USDT,DOGE/USDT,DYDX/USDT,FET/USDT,GALA/USDT,ICP/USDT,NEAR/USDT --days 365 --capital 10000

# Forward test grid_atr (365 derniers jours)
uv run python -m scripts.portfolio_backtest --strategy grid_atr --assets BTC/USDT,ETH/USDT,DOGE/USDT --days 365 --capital 10000 --save --label "forward_test_2025"

# grid_boltrend sur 6 assets, 730 jours
uv run python -m scripts.portfolio_backtest --strategy grid_boltrend --assets BTC/USDT,ETH/USDT,DOGE/USDT,DYDX/USDT,LINK/USDT --capital 1000 --days 730

# Multi-strat√©gie (grid_atr + grid_boltrend)
uv run python -m scripts.portfolio_backtest --strategies "grid_atr:BTC/USDT,ETH/USDT+grid_boltrend:DOGE/USDT,LINK/USDT" --capital 10000 --days 365

# Comparaison de leverages sans toucher au YAML
uv run python -m scripts.portfolio_backtest --capital 1000 --leverage 3
uv run python -m scripts.portfolio_backtest --capital 1000 --leverage 5
uv run python -m scripts.portfolio_backtest --capital 1000 --leverage 6

# Sortie JSON avec sauvegarde en DB
uv run python -m scripts.portfolio_backtest --strategy grid_atr --days 90 --json --save --label "q1_2025"

# A/B test d'un param√®tre (params WFO existants, un seul changement)
uv run python -m scripts.portfolio_backtest --strategy grid_atr --days auto --save --label "grid_atr_baseline_hold0"
uv run python -m scripts.portfolio_backtest --strategy grid_atr --days auto --save --label "grid_atr_test_hold48" --params "max_hold_candles=48"
uv run python -m scripts.portfolio_backtest --strategy grid_atr --days auto --save --label "grid_atr_test_hold96" --params "max_hold_candles=96"
```

**Arguments disponibles :**

| Argument | D√©faut | Description |
| --- | --- | --- |
| `--strategy` | `grid_atr` | Strat√©gie (mono-strat√©gie) |
| `--strategies` | ‚Äî | Multi-strat√©gie : `strat1:sym1,sym2+strat2:sym3` |
| `--preset` | ‚Äî | Preset pr√©d√©fini (ex: `combined`) |
| `--assets` | tous per_asset | Assets s√©par√©s par virgule |
| `--days` | `auto` | P√©riode (jours ou `auto` = max historique commun) |
| `--capital` | `10000` | Capital initial ($) |
| `--exchange` | `binance` | Source des candles |
| `--leverage` | depuis strategies.yaml | Override leverage de tous les runners |
| `--params` | ‚Äî | Override params strat√©gie : `key=val,key2=val2` |
| `--kill-switch-pct` | `45.0` | Seuil kill switch (%) |
| `--kill-switch-window` | `24` | Fen√™tre kill switch (heures) |
| `--json` | false | Sortie JSON |
| `--output` | ‚Äî | Fichier de sortie |
| `--save` | false | Sauvegarder en DB |
| `--label` | ‚Äî | Label du run |

---

## 13. Sync vers le serveur de production (sync_to_server)

Pousse les r√©sultats WFO et/ou portfolio backtests du local vers le serveur prod. Idempotent.

```powershell
# Sync tout (WFO + portfolio)
uv run python -m scripts.sync_to_server

# Sync uniquement les r√©sultats WFO
uv run python -m scripts.sync_to_server --only wfo

# Sync uniquement les portfolio backtests
uv run python -m scripts.sync_to_server --only portfolio

# Dry-run (affiche ce qui serait envoy√© sans envoyer)
uv run python -m scripts.sync_to_server --dry-run
```

**Pr√©requis :** Variables `.env` configur√©es : `SYNC_ENABLED=true`, `SYNC_SERVER_URL`, `SYNC_API_KEY`.

---

## 14. Scripts Diagnostic

### Sweep timeframes ‚Äî comparer 1h / 4h / 1d

```powershell
# grid_atr sur ETH/USDT, 730 jours
uv run python -m scripts.test_timeframe_sweep --symbol ETH/USDT --days 730 --strategy grid_atr

# grid_boltrend sur BTC/USDT
uv run python -m scripts.test_timeframe_sweep --symbol BTC/USDT --days 730 --strategy grid_boltrend

# Avec capital personnalis√©
uv run python -m scripts.test_timeframe_sweep --symbol SOL/USDT --days 365 --strategy grid_atr --capital 5000
```

**Strat√©gies support√©es :** `boltrend`, `envelope_dca`, `envelope_dca_short`, `grid_atr`, `grid_range_atr`, `grid_trend`

### Diagnostic Grid Range ATR (fast engine)

```powershell
# Run basique sur BTC/USDT
uv run python -m scripts.test_grid_range_fast --symbol BTC/USDT --days 365

# Avec param√®tres custom
uv run python -m scripts.test_grid_range_fast --symbol ETH/USDT --spacing 0.5 --num-levels 3 --tp-mode fixed_center

# Sweep de spacings automatique
uv run python -m scripts.test_grid_range_fast --symbol BTC/USDT --sweep

# Long-only ou Short-only
uv run python -m scripts.test_grid_range_fast --symbol BTC/USDT --sides long
```

### Diagnostic Grid BolTrend (trade log d√©taill√©)

```powershell
# Log des 10 premiers trades (d√©faut)
uv run python -m scripts.grid_boltrend_diagnostic

# Plus de candles et de trades
uv run python -m scripts.grid_boltrend_diagnostic --n-candles 1000 --max-trades 20

# Sauvegarder le log
uv run python -m scripts.grid_boltrend_diagnostic --output results/boltrend_log.txt
```

### Parit√© Fast Engine vs BacktestEngine (parity_check)

V√©rifie la divergence entre le fast engine (Numba/numpy) et le BacktestEngine classique.
Utile pour valider les r√©sultats WFO apr√®s une modification du fast engine.
Compare aussi les r√©sultats Bitget vs Binance.

```powershell
# V√©rification de parit√© sur vwap_rsi (d√©faut)
uv run python scripts/parity_check.py

# Strat√©gie sp√©cifique via DEFAULT_PARAMS dans le script
# (modifier les params en t√™te de fichier)
```

---

## 15. Benchmark Fast Engine

Mesure les performances du fast engine (compilation Numba + simulation). Exclut le 1er run (compilation).

```powershell
# Benchmark toutes les strat√©gies grid (200 combos, 5000 candles)
uv run python -m scripts.benchmark_fast_engine

# Benchmark avec plus de combos
uv run python -m scripts.benchmark_fast_engine --combos 500 --candles 10000

# Benchmark une strat√©gie sp√©cifique
uv run python -m scripts.benchmark_fast_engine --strategies grid_atr grid_boltrend

# Plus de runs pour la moyenne
uv run python -m scripts.benchmark_fast_engine --runs 6
```

---

## 16. Stress Test Leverage

Compare les performances d'une strat√©gie √† diff√©rents leverages sur plusieurs fen√™tres temporelles. Kill switch d√©sactiv√© pour voir le vrai max drawdown.

```powershell
# Lancer tous les tests (20 runs par d√©faut)
uv run python -m scripts.stress_test_leverage

# Une seule strat√©gie
uv run python -m scripts.stress_test_leverage --strategy grid_boltrend

# Leverages custom (pour affiner entre deux valeurs)
uv run python -m scripts.stress_test_leverage --leverages 5,7

# Une seule fen√™tre
uv run python -m scripts.stress_test_leverage --days 180

# Combin√©
uv run python -m scripts.stress_test_leverage --strategy grid_boltrend --leverages 3,5 --days 90

# Ajouter des r√©sultats √† un CSV existant
uv run python -m scripts.stress_test_leverage --strategy grid_atr --leverages 6,8 --append
```

**IMPORTANT :** Sur Windows avec Python 3.13, Numba segfault sur les fen√™tres longues. D√©sactiver le JIT :

```powershell
$env:NUMBA_DISABLE_JIT=1
uv run python -m scripts.stress_test_leverage
```

R√©sultats CSV sauvegard√©s dans `data/stress_test_results.csv`

---

## 17. Maintenance / Migration

### Migrer les JSON WFO vers la DB (Sprint 13 ‚Äî one-shot)

```powershell
# Dry-run : liste les fichiers sans importer
uv run python -m scripts.migrate_optimization --dry-run

# Import r√©el
uv run python -m scripts.migrate_optimization
```

---

## 18. Rollback d'urgence (production)

**ATTENTION : ne JAMAIS utiliser `echo "..." > .env`** ‚Äî √ßa √©crase tout le fichier (cl√©s Bitget, tokens, etc.). Toujours √©diter avec `nano`.

### D√©sactiver une strat√©gie sans red√©ployer

```bash
# Sur le serveur (SSH) ‚Äî √©diter .env manuellement
ssh jack@192.168.1.200
cd ~/scalp-radar
nano .env
# Modifier la ligne FORCE_STRATEGIES pour retirer grid_boltrend :
#   FORCE_STRATEGIES=grid_atr
# Sauvegarder et quitter (Ctrl+O, Ctrl+X)
docker compose restart backend
# V√©rifier que seul grid_atr tourne :
docker compose logs backend --tail 20 | grep "runner"
```

### Rollback git complet

```bash
cd ~/scalp-radar && docker compose down
git log --oneline -5       # identifier le commit stable
git checkout <commit-hash>
bash deploy.sh
```

### Purger l'√©tat simulator (fresh start)

```bash
cd ~/scalp-radar && bash deploy.sh --clean
```

### V√©rifier apr√®s rollback

```bash
docker compose logs backend --tail 20 | grep "runner"
curl -s http://localhost:8000/health | python3 -m json.tool
```

---

## 19. Maintenance WFO

### Purger les doublons WFO (Sprint 47b)

```powershell
uv run python -m scripts.purge_wfo_duplicates --dry-run   # aper√ßu
uv run python -m scripts.purge_wfo_duplicates             # correction
```

D√©tecte et corrige les doublons `is_latest=1` par (strategy, asset) en base. Conserve le meilleur score (`MAX(total_score)`). Supporte `--db-path` pour cibler une base sp√©cifique.

---

## 20. Scripts d'Audit & Analyse

Scripts d'analyse ponctuelle. Ne font aucune modification ‚Äî lecture seule.

### Deep Analysis post-WFO (outil DIAGNOSTIQUE ‚Äî pas un filtre)

Analyse le profil de risque par r√©gime des assets Grade A/B. Produit un verdict : VIABLE / BORDERLINE / AT RISK.
D√©tecte les red flags (SL√óleverage, r√©gimes n√©gatifs, DSR, CI95) ‚Äî √† des fins de diagnostic uniquement.

```powershell
# Analyser une strat√©gie
uv run python -m scripts.analyze_wfo_deep --strategy grid_boltrend

# Analyser toutes les strat√©gies avec r√©sultats Grade A/B en DB
uv run python -m scripts.analyze_wfo_deep --all
```

Sortie : tableau r√©capitulatif (VIABLE/BORDERLINE/AT RISK) + d√©tail par asset + note prochaine √©tape.

**Workflow post-WFO** :
```
1. WFO      ‚Üí uv run python -m scripts.optimize --strategy <n> --all-symbols
2. Apply    ‚Üí uv run python -m scripts.optimize --strategy <n> --apply   (TOUS les Grade A/B)
3. Portfolio ‚Üí uv run python -m scripts.portfolio_backtest --strategy <n> --days auto   ‚Üê LE vrai filtre
4. Deep (si portfolio √©choue) ‚Üí uv run python -m scripts.analyze_wfo_deep --strategy <n>
```

> Note : les verdicts AT RISK individuels peuvent √™tre compens√©s par la diversification.
> Exemple : grid_boltrend ‚Äî 4/6 assets AT RISK, mais portfolio +552%, DD -15.3%.

---

### Analyser une r√©gression WFO (compare les 2 derniers runs)

```powershell
# grid_atr avec levier 7 et kill switch 45%
uv run python -m scripts.analyze_wfo_regression --strategy grid_atr --leverage 7 --kill-switch 45

# Sp√©cifier les assets √† approfondir (deep dive)
uv run python -m scripts.analyze_wfo_regression --strategy grid_atr --losers NEAR/USDT DOGE/USDT
```

Sortie : diff param√©trique, analyse par r√©gime, risque SL, recommandations.

### Auditer le scoring WFO (compare 4 formules combo_score)

```powershell
uv run python -m scripts.audit_combo_score --strategy grid_atr > data/analysis/combo_score_audit.txt
uv run python -m scripts.audit_combo_score --strategy grid_boltrend
```

Sortie : changements best combo, d√©ltas Grade/Score pour chaque variante.

### V√©rifier l'alignement des fees Bitget vs mod√®le backtest

```powershell
# Derniers 7 jours avec d√©tail par symbol
uv run python -m scripts.audit_fees --days 7 -v

# Dump JSON des 3 premiers trades bruts (debug)
uv run python -m scripts.audit_fees --days 30 --debug
```

### Auditer la coh√©rence grid_states vs Bitget (fant√¥mes, orphelins, SL manquants)

```powershell
# Via API (serveur en cours ‚Äî recommand√©)
uv run python -m scripts.audit_grid_states --mode api -v

# Via fichier JSON local (serveur arr√™t√©)
uv run python -m scripts.audit_grid_states --mode file --state-file data/executor_state.json
```

### V√©rifier le sizing avant d√©ploiement live (validation minimums Bitget)

```powershell
# Lit config/strategies.yaml et .env automatiquement
uv run python scripts/check_live_sizing.py
```

Affiche capital/levels, quantit√©, notional, warning margin worst-case par asset.

### Comparer les performances WFO avant/apr√®s un re-run

```powershell
uv run python scripts/compare_wfo.py
```

Sortie : tableau Grade/Score/Sharpe/Consistency delta (vert=am√©lioration, rouge=r√©gression).

### Diagnostiquer la marge portfolio (skips par margin guard)

```powershell
# Analyse grid_atr 365 jours, levier 7 vs 6 (r√©f√©rence)
uv run python -m scripts.diagnose_margin --strategy grid_atr --leverage 7 --days 365

# grid_boltrend 90 jours
uv run python -m scripts.diagnose_margin --strategy grid_boltrend --leverage 8 --days 90
```

Sortie : skip counts par asset/guard, timeline margin utilization, comparaison leverages.

### Analyser la robustesse d'un portfolio backtest (bootstrap, stress, CVaR)

```powershell
# Analyser un backtest sauv√© par label
uv run python -m scripts.portfolio_robustness --label "grid_boltrend_6x_all_6B"

# Comparer plusieurs backtests
uv run python -m scripts.portfolio_robustness --labels "grid_atr_14assets_7x_post40a,grid_boltrend_6x_all_6B"

# Param√®tres optionnels
uv run python -m scripts.portfolio_robustness --label "grid_boltrend_6x_all_6B" \
  --n-simulations 10000 --block-size 7 --confidence 95 --seed 42 --save
```

4 m√©thodes : Block Bootstrap (CI return/DD), Regime Stress (sc√©narios march√©), Historical Stress (crashes r√©els), CVaR.
Verdict automatique GO/NO-GO (VIABLE / CAUTION / FAIL). `--save` sauvegarde en DB table `portfolio_robustness`.

### Analyser la corr√©lation entre strat√©gies

```powershell
# Lister les labels disponibles en DB
uv run python -m scripts.analyze_correlation --list

# Comparer la corr√©lation DD entre deux labels sauv√©s (√©tape 3)
uv run python -m scripts.analyze_correlation --labels "grid_atr_7x,grid_multi_tf_6x"

# Trois strat√©gies
uv run python -m scripts.analyze_correlation --labels "label1,label2,label3"
```

Mesure la corr√©lation des drawdowns entre strat√©gies (2 ou 3 labels max).
Cible : r < 0.3. Calcule aussi l'allocation optimale minimisant le DD combin√©.

**Workflow post-WFO complet (√©tapes 0-8)** :
```
0. Leverage ‚Üí calcul math√©matique (AVANT le WFO)
1. WFO      ‚Üí uv run python -m scripts.optimize --strategy <n> --all-symbols --subprocess -v
2. Apply    ‚Üí uv run python -m scripts.optimize --strategy <n> --apply
3. Portfolio ‚Üí uv run python -m scripts.portfolio_backtest --strategy <n> --days auto --save --label "<label>"
3b. Deep (DIAGNOSTIC) ‚Üí uv run python -m scripts.analyze_wfo_deep --strategy <n>
4. Stress   ‚Üí uv run python -m scripts.stress_test_leverage --strategy <n>
5. Robust.  ‚Üí uv run python -m scripts.portfolio_robustness --label "<label>" --save
6. Corr√©l.  ‚Üí uv run python -m scripts.analyze_correlation --labels "<label1>,<label2>"
7. Paper    ‚Üí enabled: true, live_eligible: false (2 semaines min, 1 mois si CAUTION)
8. Live     ‚Üí live_eligible: true (leverage progressif 3x ‚Üí 5x ‚Üí 6x)
```

---

## 20. Maintenance production

### V√©rifier la taille de la DB et du WAL

```bash
# Sur le serveur (dans le container)
docker exec scalp-radar-backend-1 ls -lh data/scalp_radar.db data/scalp_radar.db-wal data/scalp_radar.db-shm 2>/dev/null

# En local (PowerShell)
Get-Item data/scalp_radar.db, data/scalp_radar.db-wal -ErrorAction SilentlyContinue | Select-Object Name, Length
```

### WAL checkpoint manuel (r√©duire le fichier .db-wal)

```bash
# Sur le serveur (dans le container)
docker exec scalp-radar-backend-1 python3 -c "
import sqlite3
conn = sqlite3.connect('data/scalp_radar.db')
result = conn.execute('PRAGMA wal_checkpoint(TRUNCATE)').fetchone()
print(f'WAL checkpoint TRUNCATE: busy={result[0]} log={result[1]} checkpointed={result[2]}')
conn.close()
"

# TRUNCATE = vide compl√®tement le WAL (n√©cessite 0 reader actif ‚Üí faire avec backend arr√™t√©)
docker compose stop backend
sqlite3 data/scalp_radar.db "PRAGMA wal_checkpoint(TRUNCATE);"
docker compose start backend
```

> **Note :** Le WAL checkpoint PASSIVE est ex√©cut√© automatiquement toutes les heures par le backend.
> TRUNCATE est plus agressif (vide le WAL en entier) mais n√©cessite l'arr√™t du backend.

### Backup manuel de la DB

```bash
# Sur le serveur
cd ~/scalp-radar
bash scripts/backup_db.sh

# V√©rifier les backups existants
ls -lh data/backups/
```

### Installer le cron backup (Linux prod ‚Äî 1x/jour √† 3h00)

```bash
# Ouvrir le crontab
crontab -e

# Ajouter cette ligne (adapter le chemin)
0 3 * * * cd ~/scalp-radar && bash scripts/backup_db.sh >> logs/backup.log 2>&1

# V√©rifier
crontab -l | grep backup
```

### V√©rifier l'espace disque

```bash
# Via l'endpoint /health (inclut le champ "disk")
curl -s http://localhost:8000/health | python3 -m json.tool | grep -A5 '"disk"'

# Directement
df -h ~/scalp-radar/data/
du -sh ~/scalp-radar/data/

# Taille DB + WAL + backups
du -sh ~/scalp-radar/data/scalp_radar.db* ~/scalp-radar/data/backups/ 2>/dev/null
```

## 21. Multi-Executor (Sprint 36b)

### Architecture

Un Executor par strat√©gie live (enabled + live_eligible). Chaque executor peut utiliser :
- **Cl√©s globales** (fallback) : `BITGET_API_KEY`, `BITGET_SECRET`, `BITGET_PASSPHRASE`
- **Sous-compte d√©di√©** : `BITGET_API_KEY_GRID_ATR`, `BITGET_SECRET_GRID_ATR`, `BITGET_PASSPHRASE_GRID_ATR`

### Configurer un sous-compte Bitget

1. Bitget ‚Üí API Management ‚Üí Cr√©er un sous-compte
2. G√©n√©rer les cl√©s API pour le sous-compte (futures read + trade, no withdrawal)
3. Ajouter dans `.env` (serveur) :
```bash
BITGET_API_KEY_GRID_ATR=votre_api_key
BITGET_SECRET_GRID_ATR=votre_secret
BITGET_PASSPHRASE_GRID_ATR=votre_passphrase
```

### Ajouter une nouvelle strat√©gie live

1. Dans `config/strategies.yaml` : mettre `enabled: true` + `live_eligible: true`
2. (Optionnel) Cr√©er un sous-compte Bitget et ajouter les cl√©s dans `.env`
3. Red√©ployer : `ssh prod "cd ~/scalp-radar && bash deploy.sh"`

### API endpoints

```bash
# Statut agr√©g√© (tous les executors)
curl -s -H "X-API-Key: $KEY" http://localhost:8000/api/executor/status | python3 -m json.tool

# Statut d'un executor sp√©cifique
curl -s -H "X-API-Key: $KEY" "http://localhost:8000/api/executor/status?strategy=grid_atr" | python3 -m json.tool

# Reset kill switch d'un executor sp√©cifique
curl -X POST -H "X-API-Key: $KEY" "http://localhost:8000/api/executor/kill-switch/reset?strategy=grid_atr"

# Reset kill switch de tous les executors
curl -X POST -H "X-API-Key: $KEY" http://localhost:8000/api/executor/kill-switch/reset
```

### Fichiers state per-executor

```
data/executor_grid_atr_state.json       # √âtat grid_atr
data/executor_grid_multi_tf_state.json  # √âtat grid_multi_tf
data/executor_state.json                # Legacy (migration auto au 1er boot)
```

### Diagnostic

```bash
# V√©rifier quels executors tournent (dans les logs)
docker compose logs backend 2>&1 | grep "Executor\[" | tail -20

# V√©rifier si cl√©s d√©di√©es vs partag√©es
docker compose logs backend 2>&1 | grep "sous-compte" | tail -5
```
